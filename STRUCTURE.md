# Project Structure Documentation

## Overview

YouTube Comment Explorer â€” unified tool for scraping YouTube data without API:
- Channel videos metadata (newest â†’ oldest)
- Video comments (with sorting and pagination)
- Recursive channel + comments pipeline

## Directory Layout

```
youtube-comment-explorer/
â”œâ”€â”€ scrape.py                        # ğŸ¯ Main CLI entry point
â”œâ”€â”€ data/                            # ğŸ“ All exports (auto-created, gitignored)
â”‚   â”œâ”€â”€ .gitkeep                     # Keep folder in git
â”‚   â”œâ”€â”€ <channel-name>/
â”‚   â”‚   â”œâ”€â”€ videos.json              # Channel videos metadata
â”‚   â”‚   â””â”€â”€ comments/                # Per-video comments
â”‚   â”‚       â”œâ”€â”€ 0001_<videoId>.jsonl
â”‚   â”‚       â””â”€â”€ 0002_<videoId>.jsonl
â”‚   â””â”€â”€ <video-id>/
â”‚       â””â”€â”€ comments.jsonl           # Single video comments
â”œâ”€â”€ shared/                          # ğŸ”§ Common utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ youtube.py                   # Core scraping logic
â”œâ”€â”€ youtube-channel-videos/          # ğŸ“º Videos scraper module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ channel_videos.py
â”œâ”€â”€ youtube-comment-downloader/      # ğŸ’¬ Comments scraper module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py
â”‚   â””â”€â”€ downloader.py
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ LICENSE                          # MIT License
â”œâ”€â”€ README.md                        # User documentation
â”œâ”€â”€ STRUCTURE.md                     # This file
â””â”€â”€ commands.txt                     # Quick reference

```

## Module Responsibilities

### `scrape.py` (Main CLI)
- Unified command-line interface
- Three subcommands: `videos`, `comments`, `channel-comments`
- Auto-generates output paths in `data/` folder
- Orchestrates calls to scrapers

### `shared/youtube.py` (Core Utilities)
- HTTP session management with consent bypass
- HTML fetching and parsing
- `ytcfg` and `ytInitialData` extraction
- InnerTube API requests
- View count parsing
- Continuation token handling

### `youtube-channel-videos/channel_videos.py`
- `YoutubeChannelVideosScraper` class
- Fetches all videos from a channel (newest â†’ oldest)
- Handles pagination via continuation tokens
- Preserves video order from YouTube's UI
- Outputs JSON with metadata

### `youtube-comment-downloader/downloader.py`
- `YoutubeCommentDownloader` class
- Downloads comments for a video
- Supports sorting (recent/popular)
- Handles nested replies
- Outputs JSONL (line-delimited JSON)

## Data Flow

### 1. Videos Command
```
User â†’ scrape.py videos @channel
  â†“
YoutubeChannelVideosScraper
  â†“
shared.youtube (fetch_html, extract_ytcfg, inertube_ajax_request)
  â†“
data/<channel>/videos.json
```

### 2. Comments Command
```
User â†’ scrape.py comments VIDEO_ID
  â†“
YoutubeCommentDownloader
  â†“
shared.youtube (fetch_html, extract_ytcfg, inertube_ajax_request)
  â†“
data/<video_id>/comments.jsonl
```

### 3. Channel-Comments Command
```
User â†’ scrape.py channel-comments @channel
  â†“
YoutubeChannelVideosScraper (get all videos)
  â†“
data/<channel>/videos.json
  â†“
For each video:
  YoutubeCommentDownloader
    â†“
  data/<channel>/comments/NNNN_<videoId>.jsonl
```

## Key Features

### Auto-Path Generation
- Default paths: `data/<export-name>/`
- Sanitizes channel/video IDs for safe folder names
- Creates directories automatically
- Optional custom paths via `-o` or `--out-dir`

### Resume Support
- `channel-comments` skips existing comment files
- Use `--no-resume` to force re-download

### Progress Tracking
- Real-time video fetch updates
- Comment count per video
- Total statistics

### Error Handling
- Consent redirect bypass
- Robust JSON extraction
- Continuation token fallback

## Output Formats

### Videos JSON
```json
{
  "channel_id": "@channelname",
  "total_videos": 123,
  "videos": [
    {
      "order": 1,
      "video_id": "abc123",
      "title": "Video Title",
      "view_count": 123456,
      "view_count_raw": "123K views",
      "length": "10:25",
      "thumbnail_url": "https://...",
      "url": "https://www.youtube.com/watch?v=abc123",
      "channel_id": "UC..."
    }
  ]
}
```

### Comments JSONL
Each line is a JSON object:
```json
{"cid": "...", "text": "Comment text", "time": "2 days ago", "author": "@user", "channel": "UC...", "votes": "5", "replies": "2", "photo": "https://...", "heart": false, "reply": false}
```

## Dependencies

- `requests` â€” HTTP client for web scraping
- Python 3.7+ â€” Type hints, f-strings

## Git Configuration

### `.gitignore`
- Ignores `data/*` (except `.gitkeep`)
- Ignores `venv/`, `__pycache__/`, `*.pyc`
- Ignores `*.json`, `*.jsonl` (except in data/)

### Tracked Files
- Source code (`.py`)
- Documentation (`.md`, `.txt`)
- Config files (`requirements.txt`, `LICENSE`)
- `data/.gitkeep` (keeps folder in repo)

## Development Notes

### Adding New Features
1. Add shared utilities to `shared/youtube.py`
2. Extend scrapers in respective modules
3. Update CLI in `scrape.py`
4. Update README.md

### Testing
```bash
# Quick test
python scrape.py videos @test --max-videos 1
python scrape.py comments VIDEO_ID --limit 1
python scrape.py channel-comments @test --max-videos 1 --per-video-limit 1

# Check data folder
find data -type f
```

### Code Style
- Type hints for function signatures
- Docstrings for public methods
- Descriptive variable names
- Early returns for error handling
- Guard clauses for validation

## Future Enhancements

- [ ] Parallel comment downloads
- [ ] Rate limiting configuration
- [ ] Export to CSV/Parquet
- [ ] Video metadata enrichment (likes, dislikes)
- [ ] Playlist support
- [ ] Search results scraping
- [ ] Live chat archiving
- [ ] Transcript extraction

---

Last updated: 2025-12-24
